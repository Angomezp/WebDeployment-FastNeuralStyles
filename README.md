# ğŸ¨ Fast Neural Style Transfer

This project implements an **artistic style transfer system** using **PyTorch**, using the method of **Transfer-Learning** taking as the base the **[pytorch/examples](https://github.com/pytorch/examples/tree/main/fast_neural_style)** implementation of the method, which allows to combine the content of one image with the artistic style of another.  
The trained models can be used directly through a **Streamlit web app** or via Python scripts (locally), making the project interactive and easy to use both locally and in the cloud.

---

## ğŸš€ Features

- Train **style transfer networks** from scratch using **COCO 2017 dataset** or custom datasets.
- Pretrained models available for classic styles such as:
  - ğŸ¨ *Candy*
  - ğŸ¨ *Mosaic*
  - ğŸ¨ *Udnie*
  - ğŸ¨ *Rain Princess*
  - ğŸ¨ *Monet* (custom trained)
  - ğŸ¨ *Michelangelo* (custom trained)
- Two different transformation architectures:
  - **TransformerNet** â†’ lightweight style transfer (Monet)
  - **TransformerNet_v2** â†’ deeper architecture for more detailed styles (Michelangelo)
- Loss network based on **VGG19** (perceptual loss).
- Real-time **style application** through **Streamlit** web interface.
- Support for **saving and resuming checkpoints**.


---

## ğŸ“‚ Repository Structure
<pre>
  â”œâ”€â”€ images/ # Example input/output images.
  â”œâ”€â”€ pages/ # Extra Streamlit pages.
  â”œâ”€â”€ saved_models/ # Pretrained and custom-trained .pth models.
  â”œâ”€â”€ main.py # Streamlit web application.
  â”œâ”€â”€ neural_style.py # Training and evaluation script.
  â”œâ”€â”€ style.py # Helper functions for style application.
  â”œâ”€â”€ transformer_net.py # Style transfer network (base).
  â”œâ”€â”€ transformer_net_v2.py # Alternative deeper architecture.
  â”œâ”€â”€ utils.py # Utility functions (Gram matrix, normalization, etc.).
  â”œâ”€â”€ vgg16.py # VGG16 loss network (baseline).
  â”œâ”€â”€ vgg19.py # VGG19 loss network (final used).
  â”œâ”€â”€ requirements.txt # Project dependencies.
  â””â”€â”€ README.md # Project documentation.
</pre>

---

## âš™ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/Angomezp/fast_neural_style.git
cd fast_neural_style
```

Create a virtual environment and install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ‹ï¸ Training your own model.

To train a new style model:
```bash
python neural_style.py train \
  --dataset "C:/path/to/dataset" \
  --style-image "C:/path/to/style.jpg" \
  --save-model-dir saved_models \
  --checkpoint-model-dir checkpoints \
  --epochs 2 \
  --batch-size 4 \
  --image-size 256 \
  --style-size 256 \
  --accel
```

--dataset: folder containing training images (e.g., COCO 2017).

--style-image: style reference image (e.g., Monet painting).

--save-model-dir: where to save the final trained model.

--checkpoint-model-dir: save intermediate checkpoints.

--accel: use GPU acceleration if available.

## ğŸ¨ Stylization

Apply a pretrained model to a content image:

```bash
python neural_style.py eval \
  --content-image "images/input.jpg" \
  --model "saved_models/mosaic.pth" \
  --output-image "images/output.jpg"
```

## ğŸŒ Streamlit Web App

Run the interactive web app:

```bash
streamlit run main.py
```

-Upload a content image.

-Choose a style model (Candy, Mosaic, Monet, Michelangelo, etc.).

-Download or view the stylized result in real time.

## ğŸ“Š Training Configuration (default)

- Optimizer: SGD with momentum 0.99

- Learning rate: 0.05
  
- Batch size: 10

- Epochs: 50

- Loss network: VGG19

- Loss functions:

  - Content Loss: activations from relu2_2

  - Style Loss: Gram matrices across layers

  - Total Variation Loss (optional)

## ğŸ“Œ Results

Example:

| Original | Stylized(Michelangelo) |
|--------|--------|
| ![Original](images/content-images/content.jpg) | ![Stylized(Michelangelo)](images/output-images/michelangelo-content.jpg) |


	
## ğŸ“š References

Johnson, Justin, et al. "Perceptual Losses for Real-Time Style Transfer and Super-Resolution." (2016).

Ulyanov, Dmitry, et al. "Instance Normalization: The Missing Ingredient for Fast Stylization." (2017).

PyTorch official implementation: [pytorch/examples](https://github.com/pytorch/examples/tree/main/fast_neural_style)
